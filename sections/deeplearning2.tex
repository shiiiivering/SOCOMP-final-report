

\subsection{图神经网络（GNN）}



图神经网络(Graph Neural Network, GNN)是指神经网络在图上应用的统称。常见的图结构由节点和边构成，节点包含了实体(entity)信息，边包含实体间的关系信息。由于社会推荐系统中的数据天生可以表示为用户- 用户图和用户-项目图，善于整合节点信息和拓扑结构的图神经网络在近年来显示出了强大的潜力。
GNN主要包括Graph Convolutional Networks图卷积网络，Graph Attention Networks图注意力网络，Graph Autoencoder 图自编码器，Graph Generative Networks图生成网络，Graph Spatial-temporalNetworks 图时空网络 等。而其中内容最丰富的GCN又包含Spatial 和 Spectral 两种类型。

1)Spatial GCN：Message Passing Neural Networks (MPNN)、GraphSAGE。

2)Spectral GCN：Spectral CNN、Chebyshev Spectral CNN (ChebNet)、First order of ChebNet (1stChebNet) 和 Adaptive Graph Convolution Network (AGCN)。



由于图数据属于非欧几里得数据，其组织方式与传统的欧几里得结构数据有较大区别，标准的神经网络比如CNN和RNN不能够适当地处理图结构输入，它们都需要节点的特征为一定长度的向量。潜在的解决方法是选择使用邻接矩阵或拉普拉斯矩阵（图\ref{fig5}）来描述节点。

\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=0.9\linewidth]{graphs/fig5.JPG}\\
  \caption{Laplacian 矩阵}\label{fig5}
\end{figure}

进一步经过一系列的发展，可以得到Spectral-based GCN\cite{21}的迭代公式，如图\ref{fig6}，
\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=0.6\linewidth]{graphs/fig6.JPG}\\
  \caption{GCN迭代公式}\label{fig6}
\end{figure}

\begin{table}[htbp]
    \centering
    %{\begin{CJK*}{GBK}{hei}表X\quad 表说明 *表说明采用黑体*\end{CJK*}}
    \vspace {-2.5mm}
    \begin{center}
    \begin{tabular}{cccc}
    \toprule
    数据集& 节点数& 边数\\
    \hline
    Reddit& 232965& 11606919\\
    \hline
    BlogCatalog& 10312& 333983\\
    \hline
    Friendster& 117751379& 2586147869\\
    \bottomrule
    \end{tabular}

    \end{center}
    \caption{一些常见图数据集的大小}\label{tab2}
    \end{table}

\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=0.9\linewidth]{graphs/fig7.png}\\
  \caption{GraphSAGE基本思想}\label{fig7}
\end{figure}



原始的Spectral-based GCN可以较好地在小图上提取特征，但是由于依赖全图信息，在实际应用中面对大图时，如reddit、friendster等（表\ref{tab2}），GCN的训练十分具有挑战性，计算开销随层数增加而指数上升，也难以在内存中保存完整图结构以及embedding。 此外，GCN 是transductive式学习，在训练过程中都仅仅考虑当前的节点，学习目标也是直接生成当前节点的embedding，而对未知的节点，并不能起到泛化的作用，无法适应动态的图，网络结构改变以及新节点的出现都需要重新进行训练。为了解决这些问题，GraphSAGE\cite{22}(Graph SAmple and aggreGatE， 图/ref{fig7})框架提出把Embedding分为两部分：

1) Sample 采样  从大图中选取一部分节点

2) Aggregate	聚合  将采样得到的节点的特征聚合

算法\ref{fig8}外层循环k为采样深度，每循环一次都能获取到更深的邻接点的信息，k次循环就获取到了k-hop范围内的信息，然后将其聚合为新的中心节点的最终状态，最后利用最终状态进行预测和反向传播。
根据不同的聚合函数，有如下分类：

1) 均值聚合器：去中心节点和邻接点的本征向量（隐藏状态）的均值，且与原算法相比，略过了5的连接操作，直接将均值赋予$h^k_N$ （v），这样可以构成“skip-connection”，可以提高模型性能

2) LSTM聚合器：由于节点之间没有顺序，因此他们将其中的节点随机排序输入LSTM训练得到聚合的本征向量

3) 池化聚合器：在顶点和邻接点上进行element-wise 的池化操作（max-pooling、average-pooling等），实验证明max-pooling有最好的性能



\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=1\linewidth]{graphs/fig8.png}\\
  \caption{GraphSAGE Embedding 算法}\label{fig8}
\end{figure}
GraphSAGE通过采样减少参数更新时需要获取的数据量，也获得了对于动态图的适应性。类似的采样思想被其他一些模型所继承，如JK network\cite{23}、FastGCN\cite{24}、ClusterGCN\cite{25}和 GraphSAINT\cite{26}等。

\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=1\linewidth]{graphs/fig13.jpg}\\
  \caption{不同节点为中心的4-hop结构截然不同}\label{fig13}
\end{figure}

\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=1\linewidth]{graphs/fig12.jpg}\\
  \caption{Jumping Knowledge Network}\label{fig12}
\end{figure}
节点特征的学习效率通常会随着图卷积模型的加深而下降。实际上，已经证明了两层图卷积足以在GCN 和GraphSAGE中获得最佳性能 。而由于拉普拉斯平滑，更多的卷积层将会导致不同类型节点的表示更加难以分辨。从另一个角度看，核心部分中的节点和边缘节点，在相同数量的步数的传播步骤中导致不同的效果（图\ref{fig13.jpg}。对于核心部分内的节点，它们的特征影响散布的速度比边缘节点快得多，这种快速的平均导致节点的特征表示难以区分。为了减轻这个问题并使图卷积模型更深，Jumping Knowledge Network（JK network）借用残差网络的思想，自适应地选择来自不同卷积层的内容。换句话说，模型的最后一层可以有选择地独立聚合每个节点的中间表示。这逐层聚合器包括级联聚合器，最大池聚合器和LSTM-attention聚合器。此外，Jumping Knowledge Network允许与其他现有的图神经网络模型如GCN、GraphSAGE 和GAT 相结合。

FastGCN是一种结合了重要性采样的批量训练的算法，在图网络的每一层都对整个图进行采样，而非对节点采样其邻点。FastGCN将图卷积看作是一种概率测度下embedding函数的积分变换，如图\ref{fig9}，这种方式为inductive学习提供了一个理论支持。具体来说，将图的顶点解释为某种概率分布下的独立同分布的样本，并将损失和每个卷积层作为顶点embedding函数的积分。然后，通过定义样本的损失和样本梯度的蒙特卡罗近似计算积分，并且可以进一步改变采样分布（如在重要性采样中），以减小近似方差。FastGCN不仅避免了对测试数据的依赖，还为每个batch的计算产生了可控的代价花费。与GraphSAGE 的采样方法相比，FastGCN的采样方案大大减少了梯度的计算。实验结果表明，FastGCN 的每个batch的计算速度比GraphSAGE快一个数量级以上，但分类精度仍然具有很高的可比性。

\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=1\linewidth]{graphs/fig9.png}\\
  \caption{看待GCN的两种方式，图卷积与积分变换}\label{fig9}
\end{figure}

\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=1\linewidth]{graphs/fig10.png}\\
  \caption{GraphSAINT训练算法}\label{fig10}
\end{figure}
Cluster-GCN基于图聚类结构，在每个步骤中，它对一个与通过用图聚类算法来区分的密集子图相关联的一组节点进行采样，并限制该子图中的邻居搜索。这可以显著提高内存和计算效率，同时能够达到与以前算法相当的测试精度。这使得Cluster-GCN能够训练一个非常深的且具有很大规模的embeddings的网络。虽然之前的一些工作表明，深度GCN并没有提供更好的性能，但是作者发现，通过适当的优化，深度GCN可以帮助提高精度。

类似的采用子图采样的还有GraphSAINT，其的算法流程如图\ref{fig10}所示。将全图进行多次采样，在得到的sub-graph上进行全GCN，然后将多个sub-graph的信息融合起来。其中，采样是基于节点的连通性。（1）相互影响较大的节点应在同一子图中采样。（2）每条边的采样概率均不可忽略。使得神经网络能够探索整个特征和标签空间。（3）考虑降低采样方差，旨在得到最小方差的边采样概率。保留图连通性特征的采样器几乎不可避免地会在小批量估计中引入偏差。因此引入了自行设计的归一化技术，以消除偏差。最终获得的结果（图\ref{fig11}）比GraphSAGE、ClusterGCN等更好。

\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=1\linewidth]{graphs/fig11.png}\\
  \caption{GraphSAINT与其他几种GCN方法的比较}\label{fig11}
\end{figure}








Spectral-based GCN作为最初的GCN，有图信号处理的理论基础，采用滤波器的方式进行卷积，但Spectral-based GCN有如下问题：

效率：Spectral-based GCN需要特征分解，并同时处理全图数据，因此难以对大图进行缩放和并行处理；而Spatial GCN则是以batch为单位进行计算，并可以通过采样方式的改进提高效率，因此在大规模图的处理中，Spatial GCN更有优势；

通用性：Spectral-based GCN的计算基于特征值和特征向量，对图的轻微扰动则会导致特征基的变化，因此Spectral-based GCN难以对异构的图泛化；而Spatial GCN则是在每个结点进行局部卷积，权值很容易实现在不同区域共享；

灵活性：Spectral-based GCN不适用于有向图，因为有向图并没有Laplacian矩阵的明确定义；而Spatial GCN 在处理多源输入（如边特征、边方向）时更灵活，因为可以把它们合并到聚合函数Aggregation 中。

使用卷积聚合的图卷积网络GCN是一般图神经网络的一种特殊类型。也存在基于不同方式聚合的其他图神经网络变体，包括门控图神经网络\cite{27}（gated graph neural networks, GGNN）和图注意网络\cite{28}（graph attention networks, GAT）等。

\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=0.6\linewidth]{graphs/fig14.jpg}\\
  \caption{GGNN算法}\label{fig14}
\end{figure}
门控图神经网络GGNN是一种基于GRU的经典的空间域消息传递的模型，利用RNN类似原理实现了信息在图中的传递。其算法如图\ref{fig14}节点v的t+1时刻的embedding m，由其当前时刻的embedding，以及其邻居节点的当前时刻embedding，和二者的交互的边信息所决定。在输出模型部分，是对传播模型生成的每个结点的$h_v$的利用，其对应两种输出，根据目标任务不同，对输出结果有两种使用方式，分别是结点单独输出和整个图输出两种形式，结点单独输出与一般GCN相差不多，而在整张图输出一个结果时候时，会比较合理了添加了对不同结点信息的注意力，更加关注那些跟最终输出更为关联的结点。
\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=1\linewidth]{graphs/fig15.jpg}\\
  \caption{GAT的计算过程}\label{fig15}
\end{figure}

图注意力网络(GAT)使用的注意力机制可以处理任意大小输入的问题，并且关注最具有影响能力的输入。GAT 针对每一个节点运算相应的隐藏信息，在运算其相邻节点的时候引入注意力机制使其具有以下优点

1)高效：针对相邻的节点对，并且可以并行运算

2)灵活：针对有不同度（degree）的节点，可以运用任意大小的weight与之对应。（这里我们解释一个概念，节点的度degree：表示的是与这个节点相连接的节点的个数）

3)可移植：训练不需要整张图，只与相邻节点有关，可以将模型应用于从未见过的图结构数据，不需要与训练集相同。

GCN与GAT都是将邻居顶点的特征聚合到中心顶点上（一种aggregate运算），利用graph上的local stationary 学习新的顶点特征表达。不同的是GCN利用了拉普拉斯矩阵，GAT利用attention系数。一定程度上而言，GAT 会更强，因为 顶点特征之间的相关性被更好地融入到模型中。

\subsection{深度学习不适用的情形}

首先，在数据量偏小的情况下，并不适合应用深度学习。因为深度学习具有海量的参数需要训练，小的数据量容易出现过拟合的情况，降低模型对训练集以外样本的准确性。

其次，当数据不存在局部相关特性时，深度学习方法的表现也不好。深度学习之所以能在计算机视觉以及自然语言处理领域大放异彩，是因为图像和文本数据都具有局部相关性。比如图像中，相邻的点组成边，相连的边组成轮廓，可谓一个像素不能表达足够的信息，但一堆像素就能表示这是人脸还是狗头；语言中由单词组成句子，相邻的单词间存在相近的表达，同时单词间的次序一旦被打乱，那么整体所表达的信息也同时被打乱了。这些具有局部相关特性的数据，配合以特定的网络结构可以提取出其中的局部相关特性，同时配合深度架构达到层次特征的提取，从而达到令人满意的效果。而对于不具有局部相关特性的数据，没法用特定的网络拓扑来捕捉它们的信息，在深度学习中就只能用MLP来完成模型的训练，而通常MLP的效果通常要弱于GDBT , RF等传统集成树模型。

再者，不同的数据形式需要设计特定的网络结构，不存在通用的深度学习架构。图像数据被表示为二维矩阵的形式（当然三通道的图像被表示为三维矩阵），为了获取图像的局部特征，人们基于平移不变性设计出了参数共享的卷积神经网络（CNN），利用滑动窗口可以很好的捕捉局部特征，并且缩小了参数空间；文本数据被表示为序列的形式，人们基于分布式假设设计出了带滑动窗口的词嵌入技术（Word2vec），使得学到的词向量具有推理的作用；对于带有时间序列的数据，人们设计出了循环神经网络（RNN），使得参数可以受上一时刻的影响；对于图结构的数据，最近人们又设计出了图卷积神经网络（GCN）来更好的获取图结构上的特征；对于没有特殊形式的数据，深度学习不见得能更胜一筹，当人工特征工程做到一定程度后，传统模型是可以超越深度学习的。

\begin{CJK*}{GBK}{hei}
  \zihao{5}
  \vskip 1mm
  \section{总结}
  \end{CJK*}
  
社交推荐在学术界和工业界都引起了广泛的关注，并且近些年来不停的有各种各样的社交推荐系统被提出，人们还将深度学习的技术结合到社交推荐的模型中以探求其中的隐藏特征。在本文中，我们首先介绍了传统推荐算法，随后我们结合已有定义对社交推荐的定义做了一个探讨。我们将社交推荐方法归于基于内存的社交推荐和基于模型的社交推荐两类并分别做了介绍，分析其优劣。最后，我们介绍了结合深度学习技术的社交推荐并将其与传统方法作比较，分析了二者的优劣和各自的发展方向，即虽然深度学习等先进技术取得了一定的成果，但是人工特征工程结合传统模型仍旧有很高的潜力，这是深度学习暂时难以取代的。